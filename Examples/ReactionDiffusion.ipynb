{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PDE-FIND for $\\lambda - \\omega$ Reaction diffusion System\n",
    "\n",
    "Samuel Rudy, 2016\n",
    "\n",
    "This notebook demonstrates PDE-FIND on a reaction diffusion system exhibiting sprial waves on a periodic domain.  We derive PDE's for each of two quantities, having dependancies on each other; $u$ and $v$.  \n",
    "\n",
    "\\begin{align*}\n",
    "u_t &= 0.1\\nabla^2 u + \\lambda(A)u - \\omega(A)v\\\\\n",
    "v_t &= 0.1\\nabla^2 v + \\omega(A)u + \\lambda(A)v\\\\\n",
    "A^2 &= u^2 + v^2,\\, \\omega(A) = -\\beta A^2, \\lambda(A) = 1-A^2\n",
    "\\end{align*}\n",
    "\n",
    "Unlike other implmentations, we allow for $u_t$ to be dependent on derivatives of $v$, even though this is not the case in the true PDE.  The sparse regression is still able to derive the correct PDE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "pylab.rcParams['figure.figsize'] = (12, 8)\n",
    "import sys; sys.path.append('..')\n",
    "import numpy as np\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from PDE_FIND import *\n",
    "import scipy.io as sio\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unknown mat file type, version 95, 116",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-17500f65a023>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloadmat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'../Datasets/reaction_diffusion.mat'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\tools\\Anaconda3\\Lib\\site-packages\\scipy\\io\\matlab\\mio.py\u001b[0m in \u001b[0;36mloadmat\u001b[1;34m(file_name, mdict, appendmat, **kwargs)\u001b[0m\n\u001b[0;32m    221\u001b[0m     \u001b[0mvariable_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'variable_names'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    222\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0m_open_file_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mappendmat\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 223\u001b[1;33m         \u001b[0mMR\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmat_reader_factory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    224\u001b[0m         \u001b[0mmatfile_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMR\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_variables\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvariable_names\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    225\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\tools\\Anaconda3\\Lib\\site-packages\\scipy\\io\\matlab\\mio.py\u001b[0m in \u001b[0;36mmat_reader_factory\u001b[1;34m(file_name, appendmat, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m     \"\"\"\n\u001b[0;32m     71\u001b[0m     \u001b[0mbyte_stream\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile_opened\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mappendmat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m     \u001b[0mmjv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmnv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_matfile_version\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbyte_stream\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmjv\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mMatFile4Reader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbyte_stream\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile_opened\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\tools\\Anaconda3\\Lib\\site-packages\\scipy\\io\\matlab\\miobase.py\u001b[0m in \u001b[0;36mget_matfile_version\u001b[1;34m(fileobj)\u001b[0m\n\u001b[0;32m    229\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmaj_val\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    230\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 231\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Unknown mat file type, version %s, %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    232\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    233\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Unknown mat file type, version 95, 116"
     ]
    }
   ],
   "source": [
    "data = sio.loadmat('../Datasets/reaction_diffusion.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = data['t'][:,0]\n",
    "x = data['x'][0,:]\n",
    "y = data['y'][0,:]\n",
    "U = data['u']\n",
    "V = data['v']\n",
    "\n",
    "n = len(x) # also the length of y\n",
    "steps = len(t)\n",
    "dx = x[2]-x[1]\n",
    "dy = y[2]-y[1]\n",
    "dt = t[2]-t[1]\n",
    "\n",
    "pylab.rcParams['figure.figsize'] = (12, 6)\n",
    "figure()\n",
    "xx, yy = meshgrid(\n",
    "    np.arange(n)*dx,\n",
    "    np.arange(n)*dy)\n",
    "subplot(1,2,1)\n",
    "pcolor(xx,yy,U[:,:,10],cmap='coolwarm')\n",
    "title('U', fontsize = 20)\n",
    "xlabel('x', fontsize = 16)\n",
    "ylabel('y', fontsize = 16)\n",
    "subplot(1,2,2)\n",
    "pcolor(xx,yy,V[:,:,10],cmap='coolwarm')\n",
    "title('V', fontsize = 20)\n",
    "xlabel('x', fontsize = 16)\n",
    "ylabel('y', fontsize = 16)\n",
    "pylab.rcParams['figure.figsize'] = (12, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample data\n",
    "\n",
    "Since we have a very large number of data points it would take a very long time to use all of them.  Instead we'll randomly sample 150,000 (just over 1 %) of them to use in the regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample a collection of data points.  See figure 1 panel 2a.\n",
    "numpy.random.seed(0) # so that numbers in paper are reproducible\n",
    "\n",
    "num_xy = 5000 # needs to be very high to work with noise\n",
    "num_t = 30\n",
    "num_points = num_xy * num_t\n",
    "boundary = 5\n",
    "points = {}\n",
    "count = 0\n",
    "\n",
    "for p in range(num_xy):\n",
    "    x = np.random.choice(np.arange(boundary,n-boundary),1)[0]\n",
    "    y = np.random.choice(np.arange(boundary,n-boundary),1)[0]\n",
    "    for t in range(num_t):\n",
    "        points[count] = [x,y,6*t+10]\n",
    "        count = count + 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct $\\Theta (U)$ and compute $U_t$\n",
    "\n",
    "First we take the derivatives around each one of the points then combine these with a number of candidate funcitons of u and v for the PDE.  All of the candidate funcitons are listed below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take up to second order derivatives.\n",
    "u = np.zeros((num_points,1))\n",
    "v = np.zeros((num_points,1))\n",
    "ut = np.zeros((num_points,1))\n",
    "vt = np.zeros((num_points,1))\n",
    "ux = np.zeros((num_points,1))\n",
    "uy = np.zeros((num_points,1))\n",
    "uxx = np.zeros((num_points,1))\n",
    "uxy = np.zeros((num_points,1))\n",
    "uyy = np.zeros((num_points,1))\n",
    "vx = np.zeros((num_points,1))\n",
    "vy = np.zeros((num_points,1))\n",
    "vxx = np.zeros((num_points,1))\n",
    "vxy = np.zeros((num_points,1))\n",
    "vyy = np.zeros((num_points,1))\n",
    "\n",
    "N = 2*boundary-1  # number of points to use in fitting\n",
    "Nt = N\n",
    "deg = 4 # degree of polynomial to use\n",
    "\n",
    "for p in points.keys():\n",
    "    \n",
    "    [x,y,t] = points[p]\n",
    "    \n",
    "    # value of function\n",
    "    u[p] = U[x,y,t]\n",
    "    v[p] = V[x,y,t]\n",
    "    \n",
    "    # time derivatives\n",
    "    ut[p] = PolyDiffPoint(U[x,y,t-(Nt-1)/2:t+(Nt+1)/2], np.arange(Nt)*dt, deg, 1)[0]\n",
    "    vt[p] = PolyDiffPoint(V[x,y,t-(Nt-1)/2:t+(Nt+1)/2], np.arange(Nt)*dt, deg, 1)[0]\n",
    "    \n",
    "    # spatial derivatives\n",
    "    ux_diff = PolyDiffPoint(U[x-(N-1)/2:x+(N+1)/2,y,t], np.arange(N)*dx, deg, 2)\n",
    "    uy_diff = PolyDiffPoint(U[x,y-(N-1)/2:y+(N+1)/2,t], np.arange(N)*dy, deg, 2)\n",
    "    vx_diff = PolyDiffPoint(V[x-(N-1)/2:x+(N+1)/2,y,t], np.arange(N)*dx, deg, 2)\n",
    "    vy_diff = PolyDiffPoint(V[x,y-(N-1)/2:y+(N+1)/2,t], np.arange(N)*dy, deg, 2)\n",
    "    ux_diff_yp = PolyDiffPoint(U[x-(N-1)/2:x+(N+1)/2,y+1,t], np.arange(N)*dx, deg, 2)\n",
    "    ux_diff_ym = PolyDiffPoint(U[x-(N-1)/2:x+(N+1)/2,y-1,t], np.arange(N)*dx, deg, 2)\n",
    "    vx_diff_yp = PolyDiffPoint(V[x-(N-1)/2:x+(N+1)/2,y+1,t], np.arange(N)*dx, deg, 2)\n",
    "    vx_diff_ym = PolyDiffPoint(V[x-(N-1)/2:x+(N+1)/2,y-1,t], np.arange(N)*dx, deg, 2)\n",
    "    \n",
    "    ux[p] = ux_diff[0]\n",
    "    uy[p] = uy_diff[0]\n",
    "    uxx[p] = ux_diff[1]\n",
    "    uxy[p] = (ux_diff_yp[0]-ux_diff_ym[0])/(2*dy)\n",
    "    uyy[p] = uy_diff[1]\n",
    "    \n",
    "    vx[p] = vx_diff[0]\n",
    "    vy[p] = vy_diff[0]\n",
    "    vxx[p] = vx_diff[1]\n",
    "    vxy[p] = (vx_diff_yp[0]-vx_diff_ym[0])/(2*dy)\n",
    "    vyy[p] = vy_diff[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Form a huge matrix using up to quadratic polynomials in all variables.\n",
    "X_data = np.hstack([u,v])\n",
    "X_ders = np.hstack([np.ones((num_points,1)), ux, uy, uxx, uxy, uyy, vx, vy, vxx, vxy, vyy])\n",
    "X_ders_descr = ['','u_{x}', 'u_{y}','u_{xx}','u_{xy}','u_{yy}','v_{x}', 'v_{y}','v_{xx}','v_{xy}','v_{yy}']\n",
    "X, description = build_Theta(X_data, X_ders, X_ders_descr, 3, data_description = ['u','v'])\n",
    "['1'] + description[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solve for $\\xi$\n",
    "\n",
    "TrainSTRidge splits the data up into 80% for training and 20% for validation.  It searches over various tolerances in the STRidge algorithm and finds the one with the best performance on the validation set, including an $\\ell^0$ penalty for $\\xi$ in the loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = TrainSTRidge(X,ut,10**-5,1)\n",
    "print_pde(c, description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = TrainSTRidge(X,vt,10**-5,1)\n",
    "print_pde(c, description, ut = 'v_t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "err = abs(np.array([(0.1-0.099977)*100/0.1,  (0.1-0.100033)*100/0.1,\n",
    "                    (0.1-0.100009)*100/0.1,  (0.1-0.099971)*100/0.1,\n",
    "                    (1-0.999887)*100,        (1-1.000335)*100,\n",
    "                    (1-0.999906)*100,        (1-0.999970)*100,\n",
    "                    (1-0.999980)*100,        (1-0.999978)*100,\n",
    "                    (1-0.999976)*100,        (1-1.000353)*100,\n",
    "                    (1-0.999923)*100,        (1-1.000332)*100]))\n",
    "print (mean(err))\n",
    "print (std(err))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify the dynamics using the same dataset but with artificial noise\n",
    "\n",
    "In all other examples, we used 1% of the standard deviation of the solution for the magnitude of the noise added.  Even with using many more points, we weren't able to identify the correct dynamics with that noise level.  Instead we use 0.5%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now try adding noise.\n",
    "numpy.random.seed(0)\n",
    "Un = U + 0.005*std(U)*np.random.randn(n,n,steps)\n",
    "Vn = V + 0.005*std(V)*np.random.randn(n,n,steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Denoise via SVD\n",
    "\n",
    "Denoise via taking SVD and truncating where singular values flatten off."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Denoise using POD.\n",
    "FUn = Un.reshape(n**2,steps)\n",
    "FVn = Vn.reshape(n**2,steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uun,usn,uvn = np.linalg.svd(FUn, full_matrices = False)\n",
    "vun,vsn,vvn = np.linalg.svd(FVn, full_matrices = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "semilogy(usn)\n",
    "semilogy(vsn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = 15\n",
    "Un = (uun[:,:dim].dot(np.diag(usn[:dim]).dot(uvn[:dim,:]))).reshape(n,n,steps)\n",
    "Vn = (vun[:,:dim].dot(np.diag(vsn[:dim]).dot(vvn[:dim,:]))).reshape(n,n,steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've denoised the data (atleast somewhat) we just proceed as we did for the clean data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take up to second order derivatives.\n",
    "un = np.zeros((num_points,1))\n",
    "vn = np.zeros((num_points,1))\n",
    "utn = np.zeros((num_points,1))\n",
    "vtn = np.zeros((num_points,1))\n",
    "uxn = np.zeros((num_points,1))\n",
    "uyn = np.zeros((num_points,1))\n",
    "uxxn = np.zeros((num_points,1))\n",
    "uxyn = np.zeros((num_points,1))\n",
    "uyyn = np.zeros((num_points,1))\n",
    "vxn = np.zeros((num_points,1))\n",
    "vyn = np.zeros((num_points,1))\n",
    "vxxn = np.zeros((num_points,1))\n",
    "vxyn = np.zeros((num_points,1))\n",
    "vyyn = np.zeros((num_points,1))\n",
    "\n",
    "N = 2*boundary-1  # number of points to use in fitting polynomial for spatial derivative\n",
    "Nt = N # and for time derivatives\n",
    "deg = 4 # degree of polynomial to use\n",
    "\n",
    "for p in points.keys():\n",
    "    \n",
    "    [x,y,t] = points[p]\n",
    "    \n",
    "    # value of function\n",
    "    un[p] = Un[x,y,t]\n",
    "    vn[p] = Vn[x,y,t]\n",
    "    \n",
    "    # time derivatives\n",
    "    utn[p] = PolyDiffPoint(Un[x,y,t-(Nt-1)/2:t+(Nt+1)/2], np.arange(Nt)*dt, deg, 1)[0]\n",
    "    vtn[p] = PolyDiffPoint(Vn[x,y,t-(Nt-1)/2:t+(Nt+1)/2], np.arange(Nt)*dt, deg, 1)[0]\n",
    "    \n",
    "    # spatial derivatives\n",
    "    ux_diff_n = PolyDiffPoint(Un[x-(N-1)/2:x+(N+1)/2,y,t], np.arange(N)*dx, deg, 2)\n",
    "    uy_diff_n = PolyDiffPoint(Un[x,y-(N-1)/2:y+(N+1)/2,t], np.arange(N)*dy, deg, 2)\n",
    "    vx_diff_n = PolyDiffPoint(Vn[x-(N-1)/2:x+(N+1)/2,y,t], np.arange(N)*dx, deg, 2)\n",
    "    vy_diff_n = PolyDiffPoint(Vn[x,y-(N-1)/2:y+(N+1)/2,t], np.arange(N)*dy, deg, 2)\n",
    "    ux_diff_yp_n = PolyDiffPoint(Un[x-(N-1)/2:x+(N+1)/2,y+1,t], np.arange(N)*dx, deg, 2)\n",
    "    ux_diff_ym_n = PolyDiffPoint(Un[x-(N-1)/2:x+(N+1)/2,y-1,t], np.arange(N)*dx, deg, 2)\n",
    "    vx_diff_yp_n = PolyDiffPoint(Vn[x-(N-1)/2:x+(N+1)/2,y+1,t], np.arange(N)*dx, deg, 2)\n",
    "    vx_diff_ym_n = PolyDiffPoint(Vn[x-(N-1)/2:x+(N+1)/2,y-1,t], np.arange(N)*dx, deg, 2)\n",
    "    \n",
    "    uxn[p] = ux_diff_n[0]\n",
    "    uyn[p] = uy_diff_n[0]\n",
    "    uxxn[p] = ux_diff_n[1]\n",
    "    uxyn[p] = (ux_diff_yp_n[0]-ux_diff_ym_n[0])/(2*dy)\n",
    "    uyyn[p] = uy_diff_n[1]\n",
    "    \n",
    "    vxn[p] = vx_diff_n[0]\n",
    "    vyn[p] = vy_diff_n[0]\n",
    "    vxxn[p] = vx_diff_n[1]\n",
    "    vxyn[p] = (vx_diff_yp_n[0]-vx_diff_ym_n[0])/(2*dy)\n",
    "    vyyn[p] = vy_diff_n[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Form a huge matrix using up to quadratic polynomials in all variables.\n",
    "X_data_n = np.hstack([un,vn])\n",
    "X_ders_n = np.hstack([np.ones((num_points,1)), uxn, uyn, uxxn, uxyn, uyyn, vxn, vyn, vxxn, vxyn, vyyn])\n",
    "X_ders_descr = ['','u_{x}', 'u_{y}','u_{xx}','u_{xy}','u_{yy}','v_{x}', 'v_{y}','v_{xx}','v_{xy}','v_{yy}']\n",
    "X_n, description = build_Theta(X_data_n, X_ders_n, X_ders_descr, 3, data_description = ['u','v'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lam = 10**-5\n",
    "d_tol = 1\n",
    "c = TrainSTRidge(X_n,utn,lam,d_tol)\n",
    "print_pde(c, description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lam = 10**-5\n",
    "d_tol = 1\n",
    "c = TrainSTRidge(X_n,vtn,lam,d_tol)\n",
    "print_pde(c, description, ut = 'v_t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "err = abs(np.array([(0.1-0.094870)*100/0.1,  (0.1-0.094934)*100/0.1,\n",
    "                    (0.1-0.094970)*100/0.1,  (0.1-0.094939)*100/0.1,\n",
    "                    (1-0.944877)*100,        (1-0.946222)*100,\n",
    "                    (1-0.944831)*100,        (1-0.999442)*100,\n",
    "                    (1-0.999758)*100,        (1-0.999674)*100,\n",
    "                    (1-0.999770)*100,        (1-0.946074)*100,\n",
    "                    (1-0.945130)*100,        (1-0.945752)*100]))\n",
    "print (mean(err))\n",
    "print (std(err))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
